from kafka import KafkaConsumer
from datetime import datetime
import os
import time
import config  # assuming config module is defined
from threading import Thread

class DataWriterConsumer:
    def __init__(self, topic, max_record, offset_last_path):
        self.topic = topic
        self.max_record = max_record
        self.offset_last_path = offset_last_path
        self.consumer = KafkaConsumer(self.topic, group_id='data_writer_group', bootstrap_servers=config.KAFKA_SERVER, auto_offset_reset='earliest', enable_auto_commit=True)  # Enable auto commit
        self.log_folder = None
        self.event = None  # assuming the event variable is defined

    def read_offsetlast(self, path):
        # Implement your logic to read the last offset from the file
        pass

    def write_data(self, data):
        # Implement your logic to write data to the file
        print("Writing data:", data)

    def get_create_log_folder(self):
        # Implement your logic to get or create the log folder
        pass

    def upload_minio(self, folder_path):
        # Implement your logic to upload folder to Minio
        print("Uploading to Minio:", folder_path)

    def process_messages(self):
        print("===Upload Topic: ", datetime.now(), self.topic)

        offset_last_get = self.read_offsetlast(self.offset_last_path)
        if offset_last_get is None:
            offset_last_get = 0

        self.log_folder = self.get_create_log_folder()
        count = 0

        print("== after process kafka message in consumer==", datetime.now(), self.topic)

        for kafka_message in self.consumer:
            t1 = time.time()
            print("Consumer process message: ", datetime.now(), self.topic, kafka_message.value.decode())

            if self.event.is_set():
                break

            if not os.path.isdir(self.log_folder):
                self.log_folder = self.get_create_log_folder()

            data = kafka_message.value.decode()
            self.write_data(data)
            t2 = time.time()
            print("Write_data: ", datetime.now(), self.topic, t2 - t1)
            count += 1

            if count == self.max_record or kafka_message.offset == self.consumer.position(kafka_message.partition).offset - 1:
                self.upload_minio(self.log_folder)
                count = 0
                self.log_folder = self.get_create_log_folder()
                t3 = time.time()
                print("Write_data offset: ", datetime.now(), self.topic, t3 - t2)

            if self.consumer.position(kafka_message.partition).offset > self.consumer.end_offsets([kafka_message.partition])[kafka_message.partition] - 1:
                self.send_campaigmgt(data)
            
            time.sleep(0.01)

# Usage
data_writer_consumer = DataWriterConsumer("your_topic", 100, "your_offset_last_path")

# Start the consumer in a separate thread or process
data_writer_consumer_thread = Thread(target=data_writer_consumer.process_messages)
data_writer_consumer_thread.start()

data_writer_consumer_thread.join()



